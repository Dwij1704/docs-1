---
title: 'Deploy Engine'
description: 'Deploy a local xpander.ai engine using Docker'
---

# Deploy Engine Command

The `engine deploy` command helps you set up and deploy a local xpander.ai engine using Docker Compose.

## Usage

```bash
xpander engine deploy [--compose-file <file>]
```

## Options

| Option | Description |
| --- | --- |
| `--compose-file <file>` | Optional. Specify a custom Docker Compose file path |

## Prerequisites

- Docker installed and running
- Docker Compose v2.0 or later
- At least 4GB of available RAM
- 10GB of free disk space

## Examples

### Default Deployment

```bash
xpander engine deploy
```

### Custom Compose File

```bash
xpander engine deploy --compose-file ./my-compose.yml
```

## Response

The command provides real-time feedback during deployment:

```bash
Deploying local xpander.ai engine...

Step 1/4: Validating system requirements
✓ Docker available
✓ System resources sufficient
✓ Ports available

Step 2/4: Pulling container images
Pulling xpander-core     ... done
Pulling xpander-redis    ... done
Pulling xpander-postgres ... done

Step 3/4: Starting services
Creating network xpander_network     ... done
Creating container xpander-redis     ... done
Creating container xpander-postgres  ... done
Creating container xpander-core      ... done

Step 4/4: Verifying deployment
✓ All services healthy
✓ API endpoint responding
✓ Database initialized

Local engine successfully deployed!
Engine URL: http://localhost:8080
```

## Notes

- The default deployment includes:
  - Core engine service
  - Redis for caching
  - PostgreSQL for persistence
- The engine will be available at `http://localhost:8080`
- Use `xpander engine status` to verify the deployment
- To stop the engine, use `docker compose down`
- Data is persisted in Docker volumes 