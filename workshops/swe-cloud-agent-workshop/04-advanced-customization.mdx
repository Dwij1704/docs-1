---
title: "Module 4: Advanced Customization (Optional)"
description: "Run your own agent loop and customize the agent further"
icon: "gear"
---

<Note>
  **Module Summary**

  - **Goal**: Customize agent loops and run advanced local implementations
  - **Estimated Time**: 45-60 minutes
  - **Prerequisites**: Python knowledge, completed Modules 1-3
</Note>

## Custom Agent Loop

### 1. Local Agent Development
```bash
# Clone xpander agent template
git clone https://github.com/xpander-ai/agent-template
cd agent-template
pip install -r requirements.txt
```

### 2. Custom Loop Implementation
```python
# custom_swe_agent.py
from xpander_sdk import XpanderClient, Agent
import openai

class CustomSWEAgent:
    def __init__(self, config):
        self.xpander = XpanderClient(api_key=config['xpander_api_key'])
        self.agent = self.xpander.agents.get(config['agent_id'])
        self.openai = openai.OpenAI(api_key=config['openai_api_key'])
        
    def custom_loop(self, user_input: str):
        # 1. Add custom preprocessing
        processed_input = self.preprocess_input(user_input)
        
        # 2. Custom LLM interaction
        response = self.openai.chat.completions.create(
            model="gpt-4",  # Switch models here
            messages=self.agent.messages + [{"role": "user", "content": processed_input}],
            tools=self.agent.get_tools(),
            temperature=0.1  # Custom parameters
        )
        
        # 3. Custom tool execution logic
        if response.choices[0].message.tool_calls:
            results = self.custom_tool_execution(response.choices[0].message.tool_calls)
            
        # 4. Custom postprocessing
        return self.postprocess_output(response, results)
    
    def preprocess_input(self, input_text):
        # Add custom logic: validation, context injection, etc.
        return f"[SWE Task] {input_text}\nPlease provide production-ready code with tests."
    
    def custom_tool_execution(self, tool_calls):
        # Custom tool selection and execution logic
        results = []
        for call in tool_calls:
            if call.function.name.startswith('github'):
                # Custom GitHub handling
                result = self.agent.run_tools([call])
                results.append(self.enhance_github_result(result))
            else:
                # Standard execution
                result = self.agent.run_tools([call])
                results.append(result)
        return results
    
    def postprocess_output(self, response, tool_results):
        # Custom output formatting, validation, etc.
        return {
            "code": response.choices[0].message.content,
            "tool_results": tool_results,
            "custom_metadata": self.generate_metadata(response)
        }
```

### 3. LLM Model Switching
```python
# Switch between different models
MODELS = {
    "coding": "gpt-4",
    "analysis": "gpt-3.5-turbo",
    "review": "claude-3-sonnet",
    "local": "llama2:7b"  # Ollama local model
}

def get_model_for_task(task_type):
    return MODELS.get(task_type, "gpt-4")

# Usage in custom loop
model = get_model_for_task("coding")
response = self.openai.chat.completions.create(model=model, ...)
```

## Advanced Customizations

### 1. Custom Tool Creation
```python
# custom_tools.py
def create_custom_code_analyzer():
    return {
        "type": "function",
        "function": {
            "name": "analyze_code_complexity",
            "description": "Analyze code complexity and suggest optimizations",
            "parameters": {
                "type": "object",
                "properties": {
                    "code": {"type": "string"},
                    "language": {"type": "string"}
                }
            }
        }
    }

def execute_custom_tool(tool_name, parameters):
    if tool_name == "analyze_code_complexity":
        # Custom implementation
        return analyze_complexity(parameters["code"], parameters["language"])
```

### 2. Agent Workflow Customization
```python
# Custom multi-step workflow
class WorkflowOrchestrator:
    def __init__(self, agents):
        self.agents = agents
        
    def execute_swe_workflow(self, task):
        # Step 1: Analysis
        analysis = self.agents['analyzer'].process(task)
        
        # Step 2: Implementation (custom logic)
        if analysis['complexity'] > 0.7:
            impl = self.agents['senior_dev'].process(task)
        else:
            impl = self.agents['junior_dev'].process(task)
            
        # Step 3: Review
        review = self.agents['reviewer'].process(impl)
        
        # Step 4: Final output
        return self.combine_results(analysis, impl, review)
```

### 3. Local Model Integration
```python
# Integrate local models (Ollama, etc.)
import requests

class LocalModelClient:
    def __init__(self, base_url="http://localhost:11434"):
        self.base_url = base_url
        
    def generate(self, prompt, model="codellama:7b"):
        response = requests.post(f"{self.base_url}/api/generate", json={
            "model": model,
            "prompt": prompt,
            "stream": False
        })
        return response.json()['response']

# Use in custom agent
local_model = LocalModelClient()
code = local_model.generate(f"Write a Python function for: {task}")
```

## Deployment Options

### 1. Local Development Server
```python
# local_server.py
from flask import Flask, request, jsonify
from custom_swe_agent import CustomSWEAgent

app = Flask(__name__)
agent = CustomSWEAgent(config)

@app.route('/execute', methods=['POST'])
def execute_task():
    task = request.json['input']
    result = agent.custom_loop(task)
    return jsonify(result)

if __name__ == '__main__':
    app.run(debug=True, port=8000)
```

### 2. Docker Deployment
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["python", "local_server.py"]
```

### 3. Production Scaling
```yaml
# docker-compose.yml
version: '3.8'
services:
  swe-agent:
    build: .
    ports:
      - "8000:8000"
    environment:
      - XPANDER_API_KEY=${XPANDER_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./custom_configs:/app/configs
```

## Testing Custom Implementations

### 1. Unit Testing
```python
# test_custom_agent.py
import pytest
from custom_swe_agent import CustomSWEAgent

def test_custom_preprocessing():
    agent = CustomSWEAgent(test_config)
    result = agent.preprocess_input("Create a function")
    assert "[SWE Task]" in result

def test_custom_tool_execution():
    # Test custom tool logic
    pass
```

### 2. Integration Testing
```bash
# Test custom agent endpoint
curl -X POST http://localhost:8000/execute \
  -H "Content-Type: application/json" \
  -d '{"input": "Create a Python data validator"}'
```

## Key Benefits of Customization

- ðŸ”§ **Full Control**: Custom logic, model selection, and workflows
- ðŸš€ **Performance**: Optimize for your specific use cases
- ðŸ’° **Cost Control**: Use local models, custom routing
- ðŸŽ¯ **Domain Expertise**: Add specialized knowledge and tools
- ðŸ“ˆ **Scalability**: Deploy and scale according to your needs

## Next Steps

Custom implementation complete â†’ Deploy to production or continue with competition submission 