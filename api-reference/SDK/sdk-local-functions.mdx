---
title: 'SDK Local Functions'
description: 'How to use local functions with the xpander AI SDK'
---

Local functions allow your AI agents to interact with your local system through predefined functions. This enables capabilities like file operations while maintaining security through controlled access.

## Defining Local Tools

First, define your local tools with their specifications:

```python
localTools = [
    {
        "type": "function",
        "function": {
            "name": "read-file",
            "description": "Reads file content from the local system within current directory",
            "parameters": {
                "type": "object",
                "properties": {
                    "bodyParams": {
                        "type": "object",
                        "properties": {
                            "filePath": {
                                "type": "string",
                                "description": "File name to read",
                                "examples": ["file.txt", "data.csv"]
                            },
                            "outputFormat": {
                                "type": "string",
                                "description": "Output format (json/text/xml/csv)",
                                "examples": ["json", "text", "xml", "csv"]
                            }
                        },
                        "required": ["filePath"]
                    }
                },
                "required": ["bodyParams"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "write-file",
            "description": "Writes content to a file in current directory",
            "parameters": {
                "type": "object",
                "properties": {
                    "bodyParams": {
                        "type": "object",
                        "properties": {
                            "fileName": {
                                "type": "string",
                                "description": "File name to write"
                            },
                            "fileContent": {
                                "type": "string",
                                "description": "Content to write"
                            },
                            "fileType": {
                                "type": "string",
                                "description": "File format (json/txt/csv/xml)"
                            }
                        },
                        "required": ["fileName", "fileContent", "fileType"]
                    }
                },
                "required": ["bodyParams"]
            }
        }
    }
]
```

## Implementation Examples

<CodeGroup>
```python OpenAI with local tools
from xpander_sdk import XpanderClient, ToolCallType
from openai import OpenAI
import json

# Initialize clients
xpander_client = XpanderClient(api_key=xpanderAPIKey)
agent = xpander_client.agents.get(agent_id=xpanderAgentID)
openai_client = OpenAI(api_key=openAIKey)

# Add local tools to agent
agent.add_local_tools(localTools)

# Setup conversation
memory = []
memory.append({
    "role": "system",
    "content": "You are a helpful assistant with function calling and tool access. Pay attention to use write-file and read-file carefully with bodyParams, fileName, fileContent and fileType. Filetype can be only txt, csv, json or xml. You are running in While loop if you want to stop the loop please add ##FINAL ANSWER## in your answer"
})

memory.append({
    "role": "user",
    "content": "Create four hello world files, one CSV, one JSON and one XML and one text. Generate sample data for each."
})

number_of_calls = 1

while True:
    memory.append({"role": "assistant", "content": f'Step number: {number_of_calls}'})
    
    llm_response = openai_client.chat.completions.create(
        model="gpt-4",
        messages=memory,
        tools=agent.get_tools()    
    )
    
    memory.append(llm_response.choices[0].message)
    
    if llm_response.choices[0].message.tool_calls:
        tools_to_run = XpanderClient.extract_tool_calls(
            llm_response=llm_response.model_dump()
        )
        
        for tool_to_run in tools_to_run:
            if tool_to_run.type == ToolCallType.LOCAL:
                function_name = tool_to_run.name
                # Extract parameters with defaults
                body_params = tool_to_run.payload.get('bodyParams', {})
                fileName = body_params.get('fileName', 'default_file.txt')
                fileContent = body_params.get('fileContent', '')
                fileType = body_params.get('fileType', 'txt')
                
                if "write-file" in function_name:
                    result = write_file(
                        file_path=fileName,
                        content=fileContent,
                        fileType=fileType
                    )
                memory.append({
                    "role": "tool",
                    "content": json.dumps(result),
                    "tool_call_id": function_name
                })
            else:
                tool_response = agent.run_tool(tool_calls=tools_to_run)
                memory.append({
                    "role": "tool",
                    "content": tool_response.result,
                    "tool_call_id": tool_response.tool_call_id
                })
    
    if llm_response.choices[0].message.content:
        if "##FINAL ANSWER##" in llm_response.choices[0].message.content:
            break
            
    number_of_calls += 1

print(llm_response.choices[0].message.content)
```

```python Ollama with local tools
from xpander_sdk import XpanderClient, LLMProvider, ToolCallType
import ollama
import json

# Initialize clients
xpander_client = XpanderClient(api_key=xpanderAPIKey)
agent = xpander_client.agents.get(agent_id=xpanderAgentID)
ollama_client = ollama.Client()

# Add local tools to agent
agent.add_local_tools(localTools)

# Setup conversation
memory = []
memory.append({
    "role": "system",
    "content": "You are a helpful assistant with function calling and tool access. Pay attention to use write-file and read-file carefully with bodyParams, fileName, fileContent and fileType. Filetype can be only txt, csv, json or xml. You are running in While loop if you want to stop the loop please add ##FINAL ANSWER## in your answer"
})

memory.append({
    "role": "user",
    "content": "Create four hello world files, one CSV, one JSON and one XML and one text. Generate sample data for each. Example CSV data MUST BE in string 'Name,Age\nAlice,25\nBob,30'"
})

number_of_calls = 1

while True:
    llm_response = ollama_client.chat(
        model="qwen2.5-coder:14b",
        messages=memory,
        tools=agent.get_tools()    
    )
    
    memory.append({"role": "assistant", "content": f'Step number: {number_of_calls}'})
    memory.append(llm_response['message'])
    
    if llm_response['message'].get('tool_calls'):
        tools_to_run = XpanderClient.extract_tool_calls(
            llm_response=llm_response,
            llm_provider=LLMProvider.OLLAMA
        )
        
        for tool_to_run in tools_to_run:
            if tool_to_run.type == ToolCallType.LOCAL:
                function_name = tool_to_run.name
                # Extract parameters with defaults
                body_params = tool_to_run.payload.get('bodyParams', {})
                fileName = body_params.get('fileName', 'default_file.txt')
                fileContent = body_params.get('fileContent', '')
                fileType = body_params.get('fileType', 'txt')
                
                if "write-file" in function_name:
                    result = write_file(
                        file_path=fileName,
                        content=fileContent,
                        fileType=fileType
                    )
                memory.append({
                    "role": "tool",
                    "content": json.dumps(result),
                    "tool_call_id": function_name
                })
            else:
                tool_response = agent.run_tool(tool_calls=tools_to_run)
                memory.append({
                    "role": "tool",
                    "content": tool_response.result,
                    "tool_call_id": tool_response.tool_call_id
                })
    
    if llm_response['message'].get('content'):
        if "##FINAL ANSWER##" in llm_response['message']['content']:
            break
            
    number_of_calls += 1

print(llm_response['message']['content'])
```
</CodeGroup>
## Key Differences Between OpenAI and Ollama Implementations

1. **Response Structure**:
   - OpenAI: Uses `llm_response.choices[0].message`
   - Ollama: Uses `llm_response['message']`

2. **Tool Call Extraction**:
   - OpenAI: Requires `.model_dump()`
   - Ollama: Requires `llm_provider=LLMProvider.OLLAMA`

3. **Model Specification**:
   - OpenAI: Uses `"gpt-4"`
   - Ollama: Uses `"qwen2.5-coder:14b"`

## Best Practices for Local Function Implementation

1. **Memory Management**:
   - Keep track of conversation steps
   - Include system prompts for context
   - Maintain tool responses in memory

2. **Error Handling**:
   - Use default values for parameters
   - Validate file operations
   - Check tool call responses

3. **Loop Control**:
   - Use clear exit conditions
   - Track number of calls
   - Include safety limits if needed

## File Operation Functions

Here are the core file operation functions used by the local tools:

```python
def write_file(file_path, content, fileType):
    """
    Writes content to a file in specified format
    
    Args:
        file_path (str): Target file path
        content (str/list): Content to write
        fileType (str): Format (json/txt/csv/xml)
    """
    # Implementation details...

def read_file(file_path, output_format=None):
    """
    Reads file content with optional format conversion
    
    Args:
        file_path (str): Source file path
        output_format (str): Desired output format
    """
    # Implementation details...
```
## Security Considerations

1. **Path Validation**: All file operations are restricted to the current working directory
2. **Format Validation**: Only allowed file formats (json/txt/csv/xml) are processed
3. **Error Handling**: Comprehensive error handling for all file operations
4. **Input Sanitization**: All inputs are validated before processing

## Best Practices

1. Always validate file paths using `is_within_current_directory()`
2. Handle file format conversions carefully
3. Implement proper error handling for all operations
4. Use appropriate content type validation
5. Keep security considerations in mind when implementing new local functions