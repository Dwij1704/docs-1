---
title: "SDK Reference"
description: "Complete reference documentation for the xpander-sdk"
icon: "code-branch"
---

# Xpander SDK Reference

This document provides comprehensive reference documentation for the xpander-sdk (v1.47.10), focusing on AI agent functionality, function calling, and state management.

## XpanderClient

The main entry point for interacting with xpander.ai.

```python
class XpanderClient:
    def __init__(
        api_key: str,
        base_url: str = "https://api.xpander.ai",
        max_retries: int = 3,
        timeout: int = 30
    )
```

### Properties

#### agents

Access agent-related operations.

```python
# Get an agent
agent = client.agents.get(agent_id="your-agent-id")

# Create a new agent
new_agent = client.agents.create(name="My Agent", type="default")

# List all agents
all_agents = client.agents.list()
```

> **Note**: The current SDK version does not include a method to delete agents. This may be available through the web interface or in future SDK versions.

### Methods

#### extract_tool_calls

Extract tool calls from LLM responses.

```python
@staticmethod
def extract_tool_calls(
    llm_response: dict, 
    llm_provider: LLMProvider = LLMProvider.OPEN_AI
) -> List[ToolCall]
```

**Parameters**:
- `llm_response`: The raw response from an LLM
- `llm_provider`: The LLM provider (OpenAI, Anthropic, etc.)

**Returns**: List of ToolCall objects

**Example**:

```python
# Using with OpenAI
response = openai_client.chat.completions.create(
    model="gpt-4o",
    messages=messages,
    tools=tools
)
tool_calls = XpanderClient.extract_tool_calls(
    llm_response=response.model_dump(),
    llm_provider=LLMProvider.OPEN_AI
)
```

#### retrieve_pending_local_tool_calls

Extract local tools that need to be executed.

```python
@staticmethod
def retrieve_pending_local_tool_calls(
    tool_calls: List[ToolCall]
) -> List[ToolCall]
```

**Parameters**:
- `tool_calls`: List of tool calls from extract_tool_calls

**Returns**: List of local ToolCall objects to be executed

**Example**:

```python
tool_calls = XpanderClient.extract_tool_calls(llm_response=response.model_dump())
local_calls = XpanderClient.retrieve_pending_local_tool_calls(tool_calls=tool_calls)

for tc in local_calls:
    # Execute local functions
    pass
```

## Agent

Represents an AI Agent with capabilities for function calling, memory management, and execution.

```python
class Agent:
    id: str
    name: str
    instructions: str
    memory: Memory  # Available after task initialization
    graph: Graph  # Available immediately for configuration
    execution: Optional[Execution]  # Available after adding a task
    messages: List[Dict]  # Available after memory initialization
    tool_choice: str  # Configuration for tool selection behavior
```

> **Important**: 
> - The agent's basic properties (`id`, `name`) are always available.
> - The `memory` and `execution` properties require initialization before they become accessible.
> - Adding a task with `add_task()` initializes the execution context.
> - Calling `memory.init_messages()` initializes the memory system.
> - To access the agent's description, use `agent.metadata.description`.

### Task Management

#### add_task

Add a task to the agent. This initializes the execution context and makes the `execution` property available.

```python
def add_task(
    self, 
    input: str,
    files: List[Dict] = None, 
    use_worker: bool = True,
    thread_id: str = None
) -> Execution
```

**Parameters**:
- `input`: The task description or user query
- `files`: Optional list of files to include with the task
- `use_worker`: Whether to use async worker processing
- `thread_id`: Optional thread ID for conversation continuity

**Returns**: Execution object representing the task

**Example**:

```python
# This initializes the execution context
execution = agent.add_task(input="Find employees of xpander.ai")

# With additional parameters
execution = agent.add_task(
    input="Analyze this document",
    files=[{"content": "document content", "name": "document.txt"}],
    use_worker=False
)

# After this, agent.execution will be available
print(f"Execution status: {agent.execution.status}")
```

#### is_finished

Check if the current task execution is finished.

```python
def is_finished(self) -> bool
```

**Returns**: True if the execution is completed, False otherwise

**Example**:

```python
while not agent.is_finished():
    # Continue execution
    pass
```

#### retrieve_execution_result

Get the result of a completed execution.

```python
def retrieve_execution_result(self) -> ExecutionResult
```

**Returns**: ExecutionResult containing status and result content

**Example**:

```python
execution_result = agent.retrieve_execution_result()
print(f"Status: {execution_result.status}")
print(f"Result: {execution_result.result}")
```

### Tool Management

#### get_tools

Get tools available to the agent in LLM-compatible format.

```python
def get_tools(
    self, 
    llm_provider: LLMProvider = LLMProvider.OPEN_AI
) -> List[Dict]
```

**Parameters**:
- `llm_provider`: The LLM provider to format tools for

**Returns**: List of tool definitions in the format required by the specified LLM

**Example**:

```python
# Get tools for OpenAI
openai_tools = agent.get_tools(llm_provider=LLMProvider.OPEN_AI)

# Get tools for other providers
gemini_tools = agent.get_tools(llm_provider=LLMProvider.GEMINI_OPEN_AI)
```

#### run_tool

Execute a single tool.

```python
def run_tool(
    self, 
    tool: ToolCall,
    payload_extension: Dict = None,
    is_multiple: bool = False
) -> ToolCallResult
```

**Parameters**:
- `tool`: ToolCall object with tool name and parameters
- `payload_extension`: Optional additional payload parameters
- `is_multiple`: Whether this is part of a multi-tool call

**Returns**: ToolCallResult with execution results

**Example**:

```python
tool_call = ToolCall(
    name="web_search",
    type=ToolCallType.XPANDER,
    payload={
        "bodyParams": {
            "query": "xpander.ai employees"
        }
    }
)
result = agent.run_tool(tool=tool_call)
print(f"Result: {result.result}")
```

#### run_tools

Execute multiple tools.

```python
def run_tools(
    self, 
    tool_calls: List[ToolCall],
    payload_extension: Dict = None
) -> List[ToolCallResult]
```

**Parameters**:
- `tool_calls`: List of ToolCall objects
- `payload_extension`: Optional additional parameters for all tools

**Returns**: List of ToolCallResult objects

**Example**:

```python
tool_calls = XpanderClient.extract_tool_calls(llm_response=response.model_dump())
results = agent.run_tools(tool_calls=tool_calls)
```

#### add_local_tools

Add local Python functions as tools.

```python
def add_local_tools(self, tools: List[Dict]) -> None
```

**Parameters**:
- `tools`: List of tool declarations with functions

**Example**:

```python
def multiply(a: int, b: int) -> int:
    return a * b

local_tools = [{
    "declaration": {
        "type": "function",
        "function": {
            "name": "multiply",
            "description": "Multiply two integers",
            "parameters": {
                "type": "object",
                "properties": {
                    "a": {"type": "integer"},
                    "b": {"type": "integer"}
                },
                "required": ["a", "b"]
            }
        }
    },
    "fn": multiply
}]

agent.add_local_tools(local_tools)
```

#### add_tool_call_results

Add results from tool calls directly to the agent's memory.

```python
def add_tool_call_results(self, tool_call_results: List[ToolCallResult]) -> None
```

**Parameters**:
- `tool_call_results`: List of ToolCallResult objects

**Example**:

```python
# Execute tools manually
results = [
    ToolCallResult(
        function_name="web_search",
        tool_call_id="12345",
        is_success=True,
        result="Search results for xpander.ai"
    )
]

# Add results to agent memory
agent.add_tool_call_results(tool_call_results=results)
```

### Agentic Interfaces

#### retrieve_agentic_interfaces

Get available interfaces (API providers).

```python
def retrieve_agentic_interfaces(
    self,
    ignore_cache: bool = False
) -> List[AgenticInterface]
```

**Parameters**:
- `ignore_cache`: Whether to bypass cache and fetch fresh data

**Returns**: List of available AgenticInterface objects

**Example**:

```python
interfaces = agent.retrieve_agentic_interfaces()
for interface in interfaces:
    print(f"Interface: {interface.name} ({interface.id})")

# Find a specific interface
linkedin_interface = next(
    (interface for interface in interfaces if "linkedin" in interface.name.lower()),
    None
)
```

#### retrieve_agentic_operations

Get operations available for a specific interface.

```python
def retrieve_agentic_operations(
    self, 
    agentic_interface: AgenticInterface,
    ignore_cache: bool = False
) -> List[AgenticOperation]
```

**Parameters**:
- `agentic_interface`: The interface to get operations for
- `ignore_cache`: Whether to bypass cache and fetch fresh data

**Returns**: List of AgenticOperation objects

**Example**:

```python
operations = agent.retrieve_agentic_operations(agentic_interface=linkedin_interface)
for op in operations:
    print(f"Operation: {op.name} - Path: {op.path}")

# Find specific operations
search_operation = next(
    (op for op in operations if op.path == "/search-people"),
    None
)
```

#### attach_operations

Attach operations to the agent or retrieve currently attached operations.

```python
def attach_operations(self, operations: List[AgenticOperation] = None) -> List[AgenticOperation]
```

**Parameters**:
- `operations`: List of operations to attach (optional)

**Returns**: List of attached AgenticOperation objects

**Example**:

```python
# Attach operations
agent.attach_operations(operations=[search_operation, profile_operation])

# Get currently attached operations
attached_ops = agent.attach_operations()
print(f"Agent has {len(attached_ops)} attached operations")
```

### Message Management

#### add_messages

Add messages to the agent's conversation.

```python
def add_messages(self, messages: Dict) -> None
```

**Parameters**:
- `messages`: Messages to add to the conversation (e.g., LLM response)

**Example**:

```python
response = openai_client.chat.completions.create(
    model="gpt-4o",
    messages=agent.messages,
    tools=agent.get_tools()
)
agent.add_messages(messages=response.model_dump())
```

### Graph Management

The graph system allows creating structured workflows for agent execution.

#### graph.add_node

Add a node to the agent's execution graph.

```python
def add_node(self, node: GraphItem) -> GraphNode
```

**Parameters**:
- `node`: GraphItem containing node information

**Returns**: GraphNode that can be connected to other nodes

**Example**:

```python
# Add operation to graph
search_node = agent.graph.add_node(
    node=GraphItem(
        agent=agent,
        item_id=search_operation.id_to_use_on_graph,
        name=search_operation.name
    )
)

# Add local tool to graph
multiply_node = agent.graph.add_node(
    node=GraphItem(
        agent=agent,
        item_id="multiply",
        name="Multiply numbers",
        is_local_tool=True
    )
)
```

#### node.connect

Connect nodes in the graph.

```python
def connect(self, target_nodes: List[GraphNode]) -> GraphNode
```

**Parameters**:
- `target_nodes`: List of nodes to connect to

**Returns**: The source GraphNode

**Example**:

```python
# Create a sequence: search -> get_profile
search_node.connect([get_profile_node])

# Create a branching flow: analysis -> [report, alert]
analysis_node.connect([report_node, alert_node])
```

#### retrieve_node_from_graph

Find a node in the graph by its ID.

```python
def retrieve_node_from_graph(self, item_id: str) -> Optional[GraphNode]
```

**Parameters**:
- `item_id`: ID of the node to find

**Returns**: GraphNode if found, None otherwise

**Example**:

```python
node = agent.retrieve_node_from_graph(item_id="search_operation_id")
if node:
    print(f"Found node: {node.name}")
else:
    print("Node not found")
```

### Agent Deployment and Management

#### sync

Synchronize (deploy) changes to the agent.

```python
def sync(self) -> None
```

**Example**:

```python
# After configuring graph, operations, etc.
agent.sync()
```

#### update

Update agent properties.

```python
def update(self) -> None
```

**Example**:

```python
# After changing agent properties
agent.update()
```

#### load

Load an agent by ID.

```python
@classmethod
def load(cls, agent_id: str, ignore_cache: bool = False) -> Agent
```

**Parameters**:
- `agent_id`: ID of the agent to load
- `ignore_cache`: Whether to bypass cache

**Returns**: Loaded Agent object

**Example**:

```python
agent = Agent.load(agent_id="your-agent-id")
```

#### stop

Stop the current execution of the agent.

```python
def stop(self) -> None
```

**Example**:

```python
# Stop the current execution
agent.stop()
```

#### retrieve_threads_list

Retrieve conversation threads for the agent.

```python
def retrieve_threads_list(self) -> List[Dict]
```

**Returns**: List of thread information

**Example**:

```python
threads = agent.retrieve_threads_list()
print(f"Agent has {len(threads)} conversation threads")
```

## Memory

The agent's memory interface for managing conversation state.

```python
class Memory:
    def add_tool_call_results(self, tool_call_results: List[ToolCallResult]) -> None
    def init_messages(self, input: str, instructions: str, llm_provider: LLMProvider = LLMProvider.OPEN_AI) -> None
```

The Memory class provides methods to initialize and update the agent's conversation memory.

**Properties**:
None

**Methods**:

- `init_messages(input: str, instructions: str, llm_provider: LLMProvider = LLMProvider.OPEN_AI) -> None`: Initialize the agent's memory with the input message and instructions.
- `add_tool_call_results(tool_call_results: List[ToolCallResult]) -> None`: Add tool call results to the agent's memory.

**Example**:

```python
# Initialize memory with the task input
agent.memory.init_messages(
    input=agent.execution.input_message,
    instructions=agent.instructions,
    llm_provider=LLMProvider.OPEN_AI
)

# Add tool call results to memory
agent.memory.add_tool_call_results(tool_call_results=results)
```

## Complete Example: Building a Multi-agent System

Here's a complete example showing how to create and use a multi-agent system:

```python
from xpander_sdk import XpanderClient, GraphItem, ToolCall, ToolCallType, LLMProvider
from openai import OpenAI
from dotenv import load_dotenv
from os import environ

# Load environment variables
load_dotenv()
XPANDER_API_KEY = environ["XPANDER_API_KEY"]
OPENAI_API_KEY = environ["OPENAI_API_KEY"]

# Initialize clients
xpander_client = XpanderClient(api_key=XPANDER_API_KEY)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# Create the main agent
main_agent = xpander_client.agents.create(
    name="Research Coordinator",
    type="default"
)
# Access description through metadata
print(f"Agent description: {main_agent.metadata.description}")

# Get available interfaces
interfaces = main_agent.retrieve_agentic_interfaces()

# Find relevant interfaces
linkedin_interface = next(
    (interface for interface in interfaces if "linkedin" in interface.name.lower()),
    None
)
web_interface = next(
    (interface for interface in interfaces if "web" in interface.name.lower()),
    None
)

# Get operations for each interface
if linkedin_interface and web_interface:
    linkedin_operations = main_agent.retrieve_agentic_operations(
        agentic_interface=linkedin_interface
    )
    web_operations = main_agent.retrieve_agentic_operations(
        agentic_interface=web_interface
    )
    
    # Find specific operations
    linkedin_search = next(
        (op for op in linkedin_operations if "search" in op.name.lower()),
        None
    )
    web_search = next(
        (op for op in web_operations if "search" in op.name.lower()),
        None
    )
    
    # Attach operations to agent
    main_agent.attach_operations(operations=[linkedin_search, web_search])
    
    # Create graph structure
    web_node = main_agent.graph.add_node(
        node=GraphItem(
            agent=main_agent,
            item_id=web_search.id_to_use_on_graph,
            name=web_search.name
        )
    )
    
    linkedin_node = main_agent.graph.add_node(
        node=GraphItem(
            agent=main_agent,
            item_id=linkedin_search.id_to_use_on_graph,
            name=linkedin_search.name
        )
    )
    
    # Define execution flow
    web_node.connect([linkedin_node])
    
    # Deploy the agent
    main_agent.sync()
    
    # Add a task to initialize the execution context
    main_agent.add_task(
        input="Research AI startups in San Francisco and find their key employees"
    )
    
    # Initialize memory with the task input
    main_agent.memory.init_messages(
        input=main_agent.execution.input_message,
        instructions=main_agent.instructions,
        llm_provider=LLMProvider.OPEN_AI
    )
    
    # Run the agent
    while not main_agent.is_finished():
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=main_agent.messages,
            tools=main_agent.get_tools(),
            tool_choice=main_agent.tool_choice,
            temperature=0.0
        )
        
        # Add LLM response to memory
        main_agent.add_messages(messages=response.model_dump())
        
        # Extract and execute tool calls
        tool_calls = XpanderClient.extract_tool_calls(
            llm_response=response.model_dump(),
            llm_provider=LLMProvider.OPEN_AI
        )
        
        # Run tools
        results = main_agent.run_tools(tool_calls=tool_calls)
    
    # Get result
    result = main_agent.retrieve_execution_result()
    print(f"Status: {result.status}")
    print(f"Result: {result.result}")
```

## Data Classes

### ToolCall

Represents a call to execute a tool.

```python
class ToolCall:
    name: str  # Name of the tool to call
    type: ToolCallType  # XPANDER or LOCAL
    payload: Dict  # Parameters for the tool
    tool_call_id: str  # Unique ID for the call
```

### ToolCallResult

Result of a tool execution.

```python
class ToolCallResult:
    function_name: str  # Name of the executed function
    tool_call_id: str  # ID of the tool call
    is_success: bool  # Whether execution succeeded
    result: Any  # Result data if successful
    error: Optional[str]  # Error message if failed
```

### AgenticInterface

Represents an external service API.

```python
class AgenticInterface:
    id: str  # Unique identifier
    name: str  # Display name
    description: str  # Interface description
```

### AgenticOperation

A specific operation available in an interface.

```python
class AgenticOperation:
    id: str  # Unique identifier
    name: str  # Display name
    path: str  # API path
    id_to_use_on_graph: str  # ID for graph connections
```

### GraphItem

An item that can be added to the agent's workflow graph.

```python
class GraphItem:
    agent: Agent  # Reference to the parent agent
    item_id: str  # Unique identifier for the node
    name: str  # Display name
    is_local_tool: bool = False  # Whether it's a local tool
```

### ExecutionResult

Result of an agent execution.

```python
class ExecutionResult:
    status: ExecutionStatus  # CREATED, RUNNING, COMPLETED, etc.
    result: str  # Result content
    error: Optional[str]  # Error if failed
```

## Enums

### LLMProvider

```python
class LLMProvider(str, Enum):
    LANG_CHAIN = "lang_chain"  # LangChain format
    OPEN_AI = "open_ai"  # OpenAI API format
    GEMINI_OPEN_AI = "gemini_open_ai"  # Gemini's OpenAI-compatible format
    REAL_TIME_OPEN_AI = "real_time_open_ai"  # Real-time OpenAI format
    NVIDIA_NIM = "nvidia_nim"  # NVIDIA NIM format
    AMAZON_BEDROCK = "amazon_bedrock"  # Amazon Bedrock format
    OLLAMA = "ollama"  # Ollama format
    FRIENDLI_AI = "friendli_ai"  # Friendli AI format
```

> **Note on LLMProvider updates**: In previous SDK versions, different enum values were used (`OPENAI`, `ANTHROPIC`, `CLAUDE`). These have been replaced with the values shown above. In particular, use `OPEN_AI` instead of `OPENAI` and `FRIENDLI_AI` instead of `ANTHROPIC`/`CLAUDE` in all API calls.

### ToolCallType

```python
class ToolCallType(str, Enum):
    XPANDER = "xpander"  # Built-in xpander tools
    LOCAL = "local"  # Local function tools
```

### ExecutionStatus

```python
class ExecutionStatus(str, Enum):
    CREATED = "created"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
```

## Common Errors and Troubleshooting

### Error: "Execution is not initialized"

This error occurs when trying to access properties or methods that depend on an active execution context, such as `agent.memory` or `agent.execution`.

**Solution**: Initialize the execution context by adding a task:

```python
# Add a task to initialize the execution context
agent.add_task(input="Your task description")

# Now you can access execution-dependent properties
print(agent.execution.status)
```

### Error: "Memory is not initialized"

This error occurs when attempting to access `agent.messages` before initializing the memory system.

**Solution**: Initialize the memory system after adding a task:

```python
# First add a task
agent.add_task(input="Your task description")

# Then initialize memory
agent.memory.init_messages(
    input=agent.execution.input_message,
    instructions=agent.instructions,
    llm_provider=LLMProvider.OPEN_AI
)

# Now you can access messages
print(len(agent.messages))
```

### Error: "Tool not found"

This error occurs when trying to run a tool that hasn't been attached to the agent.

**Solution**: Ensure all necessary operations are attached to the agent:

```python
# Attach operations before using them
agent.attach_operations(operations=[search_operation, profile_operation])
```

### Error: "Description not found"

This error occurs when trying to access the agent's description directly.

**Solution**: Access the description through the metadata property:

```python
# Correct way to access description
description = agent.metadata.description
print(f"Agent description: {description}")
```

### Error: "Graph operations failed"

This error occurs when trying to use the graph in ways not supported by the SDK.

**Solution**: Check the graph node parameter names and structure:

```python
# Correct way to add a node (note the 'node' parameter name)
new_node = agent.graph.add_node(
    node=GraphItem(
        agent=agent,
        item_id="operation_id",
        name="Operation Name"
    )
)
``` 