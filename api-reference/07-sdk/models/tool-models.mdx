---
title: "Tool Models"
description: "Data models for working with tools in the Xpander SDK"
icon: "box"
---

The Xpander SDK uses several data models for working with tools and function calls. This documentation covers the key models used when working with tools.

## ToolCallType

An enumeration defining the different types of tool calls.

<Tabs>
  <Tab title="Python">
    <CodeBlock title="ToolCallType">
    ```python
    from xpander_sdk import ToolCallType

    # Tool call types
    print(ToolCallType.XPANDER)  # Tools provided by the Xpander platform
    print(ToolCallType.LOCAL)    # Tools implemented locally in your code
    print(ToolCallType.UNKNOWN)  # Unrecognized tool type
    ```
    </CodeBlock>
  </Tab>
  <Tab title="TypeScript">
    <CodeBlock title="ToolCallType">
    ```typescript
    import { ToolCallType } from '@xpander-ai/sdk';

    // Tool call types
    console.log(ToolCallType.XPANDER);  // Tools provided by the Xpander platform
    console.log(ToolCallType.LOCAL);    // Tools implemented locally in your code
    console.log(ToolCallType.UNKNOWN);  // Unrecognized tool type
    ```
    </CodeBlock>
  </Tab>
</Tabs>

| Enum Value             | Description                                           |
|------------------------|-------------------------------------------------------|
| `ToolCallType.XPANDER` | Tool calls executed on the Xpander platform           |
| `ToolCallType.LOCAL`   | Tool calls executed locally in your application       |
| `ToolCallType.UNKNOWN` | Unrecognized tool calls (typically a fallback value)  |

## ToolCall

Represents a function call from an LLM.

<Tabs>
  <Tab title="Python">
    <CodeBlock title="ToolCall">
    ```python
    from xpander_sdk import ToolCall, ToolCallType

    # Create a tool call for a web search
    web_search = ToolCall(
        name="web_search",
        type=ToolCallType.XPANDER,
        payload={
            "bodyParams": {
                "query": "latest AI research papers"
            }
        },
        tool_call_id="call_123456789"
    )

    # Access tool call properties
    print(f"Tool name: {web_search.name}")
    print(f"Tool type: {web_search.type}")
    print(f"Tool payload: {web_search.payload}")
    print(f"Tool call ID: {web_search.tool_call_id}")
    ```
    </CodeBlock>
  </Tab>
  <Tab title="TypeScript">
    <CodeBlock title="ToolCall">
    ```typescript
    import { ToolCall, ToolCallType } from '@xpander-ai/sdk';

    // Create a tool call for a web search
    const webSearch = new ToolCall({
        name: "web_search",
        type: ToolCallType.XPANDER,
        payload: {
            bodyParams: {
                query: "latest AI research papers"
            }
        },
        toolCallId: "call_123456789"
    });

    // Access tool call properties
    console.log(`Tool name: ${webSearch.name}`);
    console.log(`Tool type: ${webSearch.type}`);
    console.log(`Tool payload: ${JSON.stringify(webSearch.payload)}`);
    console.log(`Tool call ID: ${webSearch.toolCallId}`);
    ```
    </CodeBlock>
  </Tab>
</Tabs>

### Properties

| Property      | Type           | Description                                        |
|---------------|----------------|----------------------------------------------------|
| `name`        | string         | The name of the tool being called                  |
| `type`        | ToolCallType   | The type of the tool (XPANDER, LOCAL, etc.)        |
| `payload`     | Object         | The parameters passed to the tool                  |
| `tool_call_id`| string         | A unique identifier for the tool call              |

### Usage

Tool calls are typically extracted from LLM responses using the `extract_tool_calls()` method:

<Tabs>
  <Tab title="Python">
    <CodeBlock title="Extracting tool calls">
    ```python
    from xpander_sdk import XpanderClient, LLMProvider
    from openai import OpenAI

    # Initialize OpenAI client
    openai_client = OpenAI(api_key="your-openai-key")

    # Get LLM response with tool calls
    response = openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": "What's the weather in London?"}],
        tools=[{
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Get the current weather in a location",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "The city and state or country"
                        }
                    },
                    "required": ["location"]
                }
            }
        }]
    )

    # Extract tool calls in Xpander format
    tool_calls = XpanderClient.extract_tool_calls(
        llm_response=response.model_dump(),
        llm_provider=LLMProvider.OPEN_AI
    )

    # Process the tool calls
    for tool_call in tool_calls:
        print(f"Tool: {tool_call.name}")
        print(f"Type: {tool_call.type}")
        print(f"Payload: {tool_call.payload}")
    ```
    </CodeBlock>
  </Tab>
  <Tab title="TypeScript">
    <CodeBlock title="Extracting tool calls">
    ```typescript
    import { XpanderClient, LLMProvider } from '@xpander-ai/sdk';
    import OpenAI from 'openai';

    async function extractToolCalls() {
        // Initialize OpenAI client
        const openai = new OpenAI({ apiKey: "your-openai-key" });

        // Get LLM response with tool calls
        const response = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: [{ role: "user", content: "What's the weather in London?" }],
            tools: [{
                type: "function",
                function: {
                    name: "get_weather",
                    description: "Get the current weather in a location",
                    parameters: {
                        type: "object",
                        properties: {
                            location: {
                                type: "string",
                                description: "The city and state or country"
                            }
                        },
                        required: ["location"]
                    }
                }
            }]
        });

        // Extract tool calls in Xpander format
        const toolCalls = XpanderClient.extractToolCalls({
            llmResponse: response,
            llmProvider: LLMProvider.OPEN_AI
        });

        // Process the tool calls
        for (const toolCall of toolCalls) {
            console.log(`Tool: ${toolCall.name}`);
            console.log(`Type: ${toolCall.type}`);
            console.log(`Payload: ${JSON.stringify(toolCall.payload)}`);
        }
    }
    ```
    </CodeBlock>
  </Tab>
</Tabs>

## ToolCallResult

Represents the result of executing a tool call.

<Tabs>
  <Tab title="Python">
    <CodeBlock title="ToolCallResult">
    ```python
    from xpander_sdk import ToolCallResult

    # Create a successful tool call result
    success_result = ToolCallResult(
        function_name="web_search",
        tool_call_id="call_123456789",
        is_success=True,
        result="Found the following information: OpenAI released GPT-4 Turbo on...",
        payload={"query": "latest AI research"}
    )

    # Create a failed tool call result
    error_result = ToolCallResult(
        function_name="get_stock_price",
        tool_call_id="call_987654321",
        is_success=False,
        error="API rate limit exceeded",
        payload={"symbol": "AAPL"}
    )

    # Access result properties
    print(f"Function: {success_result.function_name}")
    print(f"Success: {success_result.is_success}")
    print(f"Result: {success_result.result[:50]}...")  # Print first 50 chars

    print(f"Function: {error_result.function_name}")
    print(f"Success: {error_result.is_success}")
    print(f"Error: {error_result.error}")
    ```
    </CodeBlock>
  </Tab>
  <Tab title="TypeScript">
    <CodeBlock title="ToolCallResult">
    ```typescript
    import { ToolCallResult } from '@xpander-ai/sdk';

    // Create a successful tool call result
    const successResult = new ToolCallResult({
        functionName: "web_search",
        toolCallId: "call_123456789",
        isSuccess: true,
        result: "Found the following information: OpenAI released GPT-4 Turbo on...",
        payload: { query: "latest AI research" }
    });

    // Create a failed tool call result
    const errorResult = new ToolCallResult({
        functionName: "get_stock_price",
        toolCallId: "call_987654321",
        isSuccess: false,
        error: "API rate limit exceeded",
        payload: { symbol: "AAPL" }
    });

    // Access result properties
    console.log(`Function: ${successResult.functionName}`);
    console.log(`Success: ${successResult.isSuccess}`);
    console.log(`Result: ${successResult.result.substring(0, 50)}...`);  // Print first 50 chars

    console.log(`Function: ${errorResult.functionName}`);
    console.log(`Success: ${errorResult.isSuccess}`);
    console.log(`Error: ${errorResult.error}`);
    ```
    </CodeBlock>
  </Tab>
</Tabs>

### Properties

| Property        | Type    | Description                                          |
|----------------|---------|------------------------------------------------------|
| `function_name` | string  | The name of the function that was called             |
| `tool_call_id`  | string  | The ID of the original tool call                     |
| `is_success`    | boolean | Whether the tool call was successful                 |
| `result`        | string  | The result of the tool call (if successful)          |
| `error`         | string  | Error message (if the tool call failed)              |
| `payload`       | Object  | The original parameters passed to the tool           |

### Usage

Tool call results are typically returned from the `run_tool()` or `run_tools()` methods:

<Tabs>
  <Tab title="Python">
    <CodeBlock title="Working with tool call results">
    ```python
    from xpander_sdk import XpanderClient, ToolCall, ToolCallType

    # Initialize client and get agent
    client = XpanderClient(api_key="your-api-key")
    agent = client.agents.get(agent_id="agent-1234")

    # Create a tool call
    tool_call = ToolCall(
        name="web_search",
        type=ToolCallType.XPANDER,
        payload={
            "bodyParams": {
                "query": "latest advances in quantum computing"
            }
        },
        tool_call_id="call_1234"
    )

    # Execute the tool
    result = agent.run_tool(tool=tool_call)

    # Process the result
    if result.is_success:
        print(f"Tool succeeded with result: {result.result[:100]}...")
    else:
        print(f"Tool failed with error: {result.error}")
    ```
    </CodeBlock>
  </Tab>
  <Tab title="TypeScript">
    <CodeBlock title="Working with tool call results">
    ```typescript
    import { XpanderClient, ToolCall, ToolCallType } from '@xpander-ai/sdk';

    async function runToolExample() {
        // Initialize client and get agent
        const client = new XpanderClient({ apiKey: "your-api-key" });
        const agent = await client.agents.get({ agentId: "agent-1234" });

        // Create a tool call
        const toolCall = new ToolCall({
            name: "web_search",
            type: ToolCallType.XPANDER,
            payload: {
                bodyParams: {
                    query: "latest advances in quantum computing"
                }
            },
            toolCallId: "call_1234"
        });

        // Execute the tool
        const result = await agent.runTool({ tool: toolCall });

        // Process the result
        if (result.isSuccess) {
            console.log(`Tool succeeded with result: ${result.result.substring(0, 100)}...`);
        } else {
            console.log(`Tool failed with error: ${result.error}`);
        }
    }
    ```
    </CodeBlock>
  </Tab>
</Tabs>

## LLMProvider

An enumeration representing different LLM providers for formatting tools and extracting tool calls.

<Tabs>
  <Tab title="Python">
    <CodeBlock title="LLMProvider">
    ```python
    from xpander_sdk import LLMProvider

    # Available LLM providers
    print(LLMProvider.OPEN_AI)        # OpenAI (GPT models)
    print(LLMProvider.FRIENDLI_AI)    # Claude (via FriendliAI)
    print(LLMProvider.GEMINI_OPEN_AI) # Google Gemini (OpenAI-compatible)
    print(LLMProvider.OLLAMA)         # Ollama (local models)
    ```
    </CodeBlock>
  </Tab>
  <Tab title="TypeScript">
    <CodeBlock title="LLMProvider">
    ```typescript
    import { LLMProvider } from '@xpander-ai/sdk';

    // Available LLM providers
    console.log(LLMProvider.OPEN_AI);        // OpenAI (GPT models)
    console.log(LLMProvider.FRIENDLI_AI);    // Claude (via FriendliAI)
    console.log(LLMProvider.GEMINI_OPEN_AI); // Google Gemini (OpenAI-compatible)
    console.log(LLMProvider.OLLAMA);         // Ollama (local models)
    ```
    </CodeBlock>
  </Tab>
</Tabs>

| Enum Value                   | Description                                     |
|------------------------------|-------------------------------------------------|
| `LLMProvider.OPEN_AI`        | OpenAI's format for GPT models                  |
| `LLMProvider.FRIENDLI_AI`    | Claude format (via FriendliAI)                  |
| `LLMProvider.GEMINI_OPEN_AI` | Google Gemini with OpenAI-compatible format     |
| `LLMProvider.OLLAMA`         | Ollama format for local models                  |

### Usage

The LLM provider is used when:
1. Initializing memory for an agent
2. Getting tools formatted for a specific LLM provider
3. Extracting tool calls from an LLM response

<Tabs>
  <Tab title="Python">
    <CodeBlock title="Using LLMProvider">
    ```python
    from xpander_sdk import XpanderClient, LLMProvider
    from openai import OpenAI

    # Initialize clients
    xpander_client = XpanderClient(api_key="your-api-key")
    openai_client = OpenAI(api_key="your-openai-key")
    agent = xpander_client.agents.get(agent_id="agent-1234")

    # Initialize memory with OpenAI format
    agent.memory.init_messages(
        input="What's the weather in Paris?",
        instructions=agent.instructions,
        llm_provider=LLMProvider.OPEN_AI
    )

    # Get tools formatted for OpenAI
    tools = agent.get_tools(llm_provider=LLMProvider.OPEN_AI)

    # Use the tools with OpenAI
    response = openai_client.chat.completions.create(
        model="gpt-4o",
        messages=agent.messages,
        tools=tools,
        tool_choice="auto"
    )

    # Extract tool calls from the response
    tool_calls = XpanderClient.extract_tool_calls(
        llm_response=response.model_dump(),
        llm_provider=LLMProvider.OPEN_AI
    )
    ```
    </CodeBlock>
  </Tab>
  <Tab title="TypeScript">
    <CodeBlock title="Using LLMProvider">
    ```typescript
    import { XpanderClient, LLMProvider } from '@xpander-ai/sdk';
    import OpenAI from 'openai';

    async function llmProviderExample() {
        // Initialize clients
        const xpanderClient = new XpanderClient({ apiKey: "your-api-key" });
        const openai = new OpenAI({ apiKey: "your-openai-key" });
        const agent = await xpanderClient.agents.get({ agentId: "agent-1234" });

        // Initialize memory with OpenAI format
        await agent.memory.initMessages({
            input: "What's the weather in Paris?",
            instructions: agent.instructions,
            llmProvider: LLMProvider.OPEN_AI
        });

        // Get tools formatted for OpenAI
        const tools = agent.getTools({ llmProvider: LLMProvider.OPEN_AI });

        // Use the tools with OpenAI
        const response = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: agent.messages,
            tools: tools,
            tool_choice: "auto"
        });

        // Extract tool calls from the response
        const toolCalls = XpanderClient.extractToolCalls({
            llmResponse: response,
            llmProvider: LLMProvider.OPEN_AI
        });
    }
    ```
    </CodeBlock>
  </Tab>
</Tabs>

## Related Resources

<CardGroup cols={2}>
  <Card title="Agent Class" icon="robot" href="/api-reference/07-sdk/agent">
    Learn about the core Agent class
  </Card>
  <Card title="Agent Tools" icon="wrench" href="/api-reference/07-sdk/agent/tools">
    Using agent tools and function calling
  </Card>
  <Card title="Memory Management" icon="brain" href="/api-reference/07-sdk/agent/memory">
    Working with agent memory
  </Card>
  <Card title="LLM Integration" icon="microchip" href="/api-reference/07-sdk/llm-integration">
    Integrating with different LLM providers
  </Card>
</CardGroup> 