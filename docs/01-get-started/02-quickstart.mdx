---
title: "Quickstart"
---

Install the xpander CLI using pip:

<CardGroup cols={2}>
  <Card 
    title="pip" 
    icon="python"
  >
    ```bash
    pip install xpander
    ```
  </Card>

  <Card 
    title="npm" 
    icon="npm"
  >
    ```bash
    npm install -g xpander
    ```
  </Card>
</CardGroup>

## Getting Started

Initialize xpander by logging in and creating your first agent:

```bash
xpander login
xpander agent new
xpander agent get
```

<CardGroup cols={2}>
  <Card 
    title="LLM Models" 
    icon="wand-magic-sparkles"
    href="#llm-models-without-agent-frameworks"
  >
    Direct integration with LLMs like GPT-4, Claude, and Gemini
  </Card>

  <Card 
    title="Agent Frameworks" 
    icon="robot"
    href="#simple-agents-with-existing-agent-frameworks"
  >
    Integration with popular frameworks like LlamaIndex, CrewAI, and Smoleagents
  </Card>
</CardGroup>

# LLM Models without Agent Frameworks
Choose this approach when you want direct control over LLM interactions and custom tool execution. Perfect for simple automations and specific use cases.

## Single Query (Quick Start)
Send one-off queries to your preferred LLM with built-in tool support.

<CodeGroup>
```python OpenAI
response = openai_client.chat.completions.create(
    model="gpt-4-turbo",
    messages=agent.messages,
    tools=agent.get_tools(llm_provider=LLMProvider.OPENAI),
    tool_choice="auto",
    temperature=0.0
)

# Process and execute tools
agent.process_llm_response(
    response.model_dump(), 
    llm_provider=LLMProvider.OPENAI
)
```

```python Gemini
response = gemini_openai_client.chat.completions.create(
    model="gemini-2.0-flash",
    messages=agent.messages,
    tools=agent.get_tools(llm_provider=LLMProvider.GEMINI_OPEN_AI),
    tool_choice="auto",
    temperature=0.0
)

# Process and execute tools
agent.process_llm_response(
    response.model_dump(), 
    llm_provider=LLMProvider.GEMINI_OPEN_AI
)
```

```python Claude
response = anthropic_client.messages.create(
    model="claude-3-opus",
    messages=agent.messages,
    tools=agent.get_tools(llm_provider=LLMProvider.ANTHROPIC),
    tool_choice="auto",
    temperature=0.0
)

# Process and execute tools
agent.process_llm_response(
    response.model_dump(), 
    llm_provider=LLMProvider.ANTHROPIC
)
```
</CodeGroup>

## Event streaming (Slack, Teams, RestAPI, Realtime voice)
Handle real-time events and messages from various platforms with continuous LLM interactions.

<CodeGroup>
```python OpenAI
def handle_event(event):
    response = openai_client.chat.completions.create(
        model="gpt-4-turbo",
        messages=agent.messages,
        tools=agent.get_tools(llm_provider=LLMProvider.OPENAI),
        tool_choice="auto",
        temperature=0.0
    )
    
    agent.process_llm_response(
        response.model_dump(), 
        llm_provider=LLMProvider.OPENAI
    )

xpander_agent.start_event_listener()
```

```python Gemini
def handle_event(event):
    response = gemini_openai_client.chat.completions.create(
        model="gemini-2.0-flash",
        messages=agent.messages,
        tools=agent.get_tools(llm_provider=LLMProvider.GEMINI_OPEN_AI),
        tool_choice="auto",
        temperature=0.0
    )
    
    agent.process_llm_response(
        response.model_dump(), 
        llm_provider=LLMProvider.GEMINI_OPEN_AI
    )

xpander_agent.start_event_listener()
```

```python Claude
def handle_event(event):
    response = anthropic_client.messages.create(
        model="claude-3-opus",
        messages=agent.messages,
        tools=agent.get_tools(llm_provider=LLMProvider.ANTHROPIC),
        tool_choice="auto",
        temperature=0.0
    )
    
    agent.process_llm_response(
        response.model_dump(), 
        llm_provider=LLMProvider.ANTHROPIC
    )

xpander_agent.start_event_listener()
```
</CodeGroup>

## Multi-Step Tasks
Break down complex tasks into manageable steps with automatic tool execution and state management.

<CodeGroup>
```python OpenAI
task = """
Find employees of xpander.ai and their roles.
Then check their LinkedIn profiles for recent updates.
"""
agent.add_task(task)

while not agent.is_finished():
    response = openai_client.chat.completions.create(
        model="gpt-4-turbo",
        messages=agent.messages,
        tools=agent.get_tools(llm_provider=LLMProvider.OPENAI),
        tool_choice="auto",
        temperature=0.0
    )
    
    agent.process_llm_response(
        response.model_dump(), 
        llm_provider=LLMProvider.OPENAI
    )
```

```python Gemini
task = """
Find employees of xpander.ai and their roles.
Then check their LinkedIn profiles for recent updates.
"""
agent.add_task(task)

while not agent.is_finished():
    response = gemini_openai_client.chat.completions.create(
        model="gemini-2.0-flash",
        messages=agent.messages,
        tools=agent.get_tools(llm_provider=LLMProvider.GEMINI_OPEN_AI),
        tool_choice="auto",
        temperature=0.0
    )
    
    agent.process_llm_response(
        response.model_dump(), 
        llm_provider=LLMProvider.GEMINI_OPEN_AI
    )
```

```python Claude
task = """
Find employees of xpander.ai and their roles.
Then check their LinkedIn profiles for recent updates.
"""
agent.add_task(task)

while not agent.is_finished():
    response = anthropic_client.messages.create(
        model="claude-3-opus",
        messages=agent.messages,
        tools=agent.get_tools(llm_provider=LLMProvider.ANTHROPIC),
        tool_choice="auto",
        temperature=0.0
    )
    
    agent.process_llm_response(
        response.model_dump(), 
        llm_provider=LLMProvider.ANTHROPIC
    )
```
</CodeGroup>

# Simple Agents with existing Agent Frameworks
Choose this approach when you want to leverage existing agent frameworks with added xpander.ai capabilities like state management, authentication, and enhanced tools.

<CodeGroup>
```python Smoleagents (Hugging Face)
query = "Hello, world! You are AI Agent with State managed by xpander.ai. You are now have access to more tools, authenticate users, and preserve state, return to tasks later"

smolagent = CodeAgent(
		    tools=[xpander_agent.get_tools("smolagents")],
		    model=LiteLLMModel(model_id=xpander.get_model()),
		)
smolagent.memory = xpander_agent.get_memory(agent.to_dict())
result = smolagent.run(query)
xpander_agent.send_result(result)
```

```python LlamaIndex
query = "Hello, world! You are AI Agent with State managed by xpander.ai. You are now have access to more tools, authenticate users, and preserve state, return to tasks later"

# Initialize LlamaIndex agent with xpander tools and memory
agent = OpenAIAgent.from_tools(
    tools=xpander_agent.get_tools("llamaindex"),
    llm=OpenAI(model=xpander.get_model()),
    memory=xpander_agent.get_memory(agent.to_dict()),
    verbose=True
)

# Run the query and send results
response = agent.chat(query)
xpander_agent.send_result(response)
```

```python CrewAI
query = "Hello, world! You are AI Agent with State managed by xpander.ai. You are now have access to more tools, authenticate users, and preserve state, return to tasks later"

# Create agent with xpander tools
agent = Agent(
    role="Assistant",
    goal="Help users with their queries",
    backstory="AI assistant with enhanced capabilities through xpander.ai",
    tools=xpander_agent.get_tools("crewai"),
    llm=xpander.get_model()
)

# Create crew with single agent and memory
crew = Crew(
    agents=[agent],
    memory=xpander_agent.get_memory(agent.to_dict())
)

# Execute task and send results
result = crew.execute(query)
xpander_agent.send_result(result)
```

</CodeGroup>

# Event streaming (Slack, Teams, RestAPI, Realtime voice)

<CodeGroup>
```python Smoleagents (Hugging Face)
def handle_event(event):
		smolagent = CodeAgent(
		    tools=[xpander_agent.get_tools("smolagents")],
		    model=LiteLLMModel(model_id=xpander.get_model()),
		)
		smolagent.memory = xpander_agent.get_memory(agent.to_dict())
    result = smolagent.run(event.payload)
    xpander_agent.send_result(result)

xpander_agent.start_event_listener()
```

```python LlamaIndex
def handle_event(event):
    agent = OpenAIAgent.from_tools(
        tools=xpander_agent.get_tools("llamaindex"),
        llm=OpenAI(model=xpander.get_model()),
        memory=xpander_agent.get_memory(agent.to_dict()),
        verbose=True
    )
    response = agent.chat(event.payload)
    xpander_agent.send_result(response)

xpander_agent.start_event_listener()
```

```python CrewAI
def handle_event(event):
    agent = Agent(
        role="Assistant",
        goal="Help users with their queries",
        backstory="AI assistant with enhanced capabilities through xpander.ai",
        tools=xpander_agent.get_tools("crewai"),
        llm=xpander.get_model()
    )
    
    crew = Crew(
        agents=[agent],
        memory=xpander_agent.get_memory(agent.to_dict())
    )
    
    result = crew.execute(event.payload)
    xpander_agent.send_result(result)

xpander_agent.start_event_listener()
```

</CodeGroup>

## Next Steps
<CardGroup cols={2}>
  <Card 
    title="Add Voice & Chat Interfaces" 
    icon="microphone"
    href="/docs/05-human-interfaces/01-voice-apis"
  >
    Add voice, chat and other human-machine interfaces to your agents
  </Card>

  <Card 
    title="Manage Multi-User State" 
    icon="users"
    href="/docs/03-ai-state-management/02-multi-agent-collaboration"
  >
    Learn how to handle state across multiple users and sessions
  </Card>

  <Card 
    title="Manage Agent Memory" 
    icon="brain"
    href="/docs/03-ai-state-management/01-single-agent-state"
  >
    Configure and manage memory state between your AI agents
  </Card>

  <Card 
    title="Add User Authentication" 
    icon="lock"
    href="/docs/04-user-authentication/01-add-provider"
  >
    Implement secure user authentication for your agents
  </Card>
</CardGroup>